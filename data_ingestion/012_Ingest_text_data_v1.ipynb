{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Text Data\n",
    "Labeled text data sometimes are in structured data format, such as reviews for sentiment analysis, news headlines for topic modeling, or documents for text classification, where you have one column for the label, one column for the text, and sometimes other columns as attributes, and you can just treat them as tabular data and ingest them as we talked about in last section. Sometimes text data, expecially raw text data comes as unstructured data and is often in .json or .txt format, and we will discuss how to ingest these types of data files into a Sagemaker Notebook in this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "\n",
    "# Get region \n",
    "session = boto3.session.Session()\n",
    "region_name = session.region_name\n",
    "\n",
    "# Get SageMaker session & default S3 bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket() # replace with your own bucket if you have one \n",
    " # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "role = get_execution_role()\n",
    "prefix = 'text_spam/spam'\n",
    "prefix_json = 'json_jeo'\n",
    "filename = 'SMSSpamCollection.txt'\n",
    "filename_json = 'JEOPARDY_QUESTIONS1.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data from Online Sources\n",
    "\n",
    "### Text data (in structured .csv format): Twitter -- sentiment140\n",
    " **Sentiment140** This is the sentiment140 dataset. It contains 1.6M tweets extracted using the twitter api . The tweets have been annotated with sentiment (0 = negative, 4 = positive) and topics (hashtags used to retrive tweets). The dataset contains the following columns:\n",
    "* `target`: the polarity of the tweet (0 = negative, 4 = positive)\n",
    "* `ids`: The id of the tweet ( 2087)\n",
    "* `date`: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "* `flag`: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "* `user`: the user that tweeted (robotickilldozr)\n",
    "* `text`: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def write_to_s3(filename, bucket, prefix):\n",
    "    key = \"{}/{}\".format(prefix,filename)\n",
    "    return boto3.Session().resource('s3').Bucket(bucket).upload_file(filename,key)\n",
    "\n",
    "def upload_to_s3(bucket, prefix, filename):\n",
    "    url = 's3://{}/{}/{}'.format(bucket, prefix, filename)\n",
    "    print('Writing to {}'.format(url))\n",
    "    write_to_s3(filename, bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-08 14:51:58--  http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip [following]\n",
      "--2020-10-08 14:51:58--  https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 81363704 (78M) [application/zip]\n",
      "Saving to: ‘sentimen140.zip’\n",
      "\n",
      "sentimen140.zip     100%[===================>]  77.59M  21.1MB/s    in 4.1s    \n",
      "\n",
      "2020-10-08 14:52:02 (19.0 MB/s) - ‘sentimen140.zip’ saved [81363704/81363704]\n",
      "\n",
      "Archive:  sentimen140.zip\n",
      "  inflating: sentiment140/testdata.manual.2009.06.14.csv  \n",
      "  inflating: sentiment140/training.1600000.processed.noemoticon.csv  \n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip -O sentimen140.zip\n",
    "# Uncompressing\n",
    "!unzip sentimen140.zip -d sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to s3://sagemaker-us-east-2-060356833389/text_sentiment140/sentiment140/training.1600000.processed.noemoticon.csv\n",
      "Writing to s3://sagemaker-us-east-2-060356833389/text_sentiment140/sentiment140/testdata.manual.2009.06.14.csv\n"
     ]
    }
   ],
   "source": [
    "#upload the files to the S3 bucket\n",
    "import glob\n",
    "csv_files = glob.glob(\"sentiment140/*.csv\")\n",
    "for filename in csv_files:\n",
    "    upload_to_s3(bucket, 'text_sentiment140', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data (in .txt format): SMS Spam data \n",
    "[SMS Spam Data](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The data composed by just one text file, where each line has the correct class followed by the raw message. We will use this data to showcase how to ingest text data in .txt format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-08 14:53:20--  http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/smsspamcollection.zip\n",
      "Resolving www.dt.fee.unicamp.br (www.dt.fee.unicamp.br)... 143.106.12.20\n",
      "Connecting to www.dt.fee.unicamp.br (www.dt.fee.unicamp.br)|143.106.12.20|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 210521 (206K) [application/zip]\n",
      "Saving to: ‘spam.zip’\n",
      "\n",
      "spam.zip            100%[===================>] 205.59K   178KB/s    in 1.2s    \n",
      "\n",
      "2020-10-08 14:53:23 (178 KB/s) - ‘spam.zip’ saved [210521/210521]\n",
      "\n",
      "Archive:  spam.zip\n",
      "  inflating: spam/readme             \n",
      "  inflating: spam/SMSSpamCollection.txt  \n"
     ]
    }
   ],
   "source": [
    "!wget http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/smsspamcollection.zip -O spam.zip\n",
    "!unzip spam.zip -d spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to s3://sagemaker-us-east-2-060356833389/text_spam/spam/SMSSpamCollection.txt\n"
     ]
    }
   ],
   "source": [
    "txt_files = glob.glob(\"spam/*.txt\")\n",
    "for filename in txt_files:\n",
    "    upload_to_s3(bucket, 'text_spam', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data (in .json format): Jeopardy Question data\n",
    "[Jeopardy Question](https://j-archive.com/) were obtained by crawling the Jeopardy question archive website. It is an unordered list of questions where each question has the following key-value pairs:\n",
    "\n",
    "* `category` : the question category, e.g. \"HISTORY\"\n",
    "* `value`: \\$ value of the question as string, e.g. \"\\$200\"\n",
    "* `question`: text of question\n",
    "* `answer` : text of answer\n",
    "* `round`: one of \"Jeopardy!\",\"Double Jeopardy!\",\"Final Jeopardy!\" or \"Tiebreaker\"\n",
    "* `show_number` : string of show number, e.g '4680'\n",
    "* `air_date` : the show air date in format YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-08 14:53:26--  http://skeeto.s3.amazonaws.com/share/JEOPARDY_QUESTIONS1.json.gz\n",
      "Resolving skeeto.s3.amazonaws.com (skeeto.s3.amazonaws.com)... 52.216.25.180\n",
      "Connecting to skeeto.s3.amazonaws.com (skeeto.s3.amazonaws.com)|52.216.25.180|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12721082 (12M) [application/json]\n",
      "Saving to: ‘JEOPARDY_QUESTIONS1.json.gz’\n",
      "\n",
      "JEOPARDY_QUESTIONS1 100%[===================>]  12.13M  15.7MB/s    in 0.8s    \n",
      "\n",
      "2020-10-08 14:53:27 (15.7 MB/s) - ‘JEOPARDY_QUESTIONS1.json.gz’ saved [12721082/12721082]\n",
      "\n",
      "Writing to s3://sagemaker-us-east-2-060356833389/json_jeo/JEOPARDY_QUESTIONS1.json\n"
     ]
    }
   ],
   "source": [
    "#json file format\n",
    "!wget http://skeeto.s3.amazonaws.com/share/JEOPARDY_QUESTIONS1.json.gz\n",
    "# Uncompressing\n",
    "!gunzip JEOPARDY_QUESTIONS1.json.gz\n",
    "filename = 'JEOPARDY_QUESTIONS1.json'\n",
    "upload_to_s3(bucket, 'json_jeo', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Data into Sagemaker Notebook\n",
    "## Method 1: Copying data to the Instance\n",
    "AWS Command Line Tools (CLI) is a easy way to copy your data from s3 to your sagemaker instance and copy files between your S3 buckets. It is a quick and easy approach when you are dealing with medium sized data files, or you are experimenting and doing exploratory analysis. The documentation can be found here https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify file names\n",
    "prefix = 'text_spam/spam'\n",
    "prefix_json = 'json_jeo'\n",
    "filename = 'SMSSpamCollection.txt'\n",
    "filename_json = 'JEOPARDY_QUESTIONS1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-2-060356833389/json_jeo/JEOPARDY_QUESTIONS1.json to text/json_jeo/JEOPARDY_QUESTIONS1.json\n"
     ]
    }
   ],
   "source": [
    "#copy data to your sagemaker instance using AWS CLI\n",
    "!aws s3 cp s3://$bucket/$prefix_json/ text/$prefix_json/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'HISTORY', 'air_date': '2004-12-31', 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\", 'value': '$200', 'answer': 'Copernicus', 'round': 'Jeopardy!', 'show_number': '4680'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data_location = \"text/{}/{}\".format(prefix_json, filename_json)\n",
    "with open(data_location) as f:\n",
    "    data = json.load(f)\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Use AWS compatible Python Packages\n",
    "The easiest way to access your files in S3 without copying files into your instance storage is to use pre-built packages which already have implemented options to access data with a specified path string. As an example the pandas library uses the URI schemes to properly identify the method of accessing the data. While file:// will look on the local file system, s3:// accesses the data through the AWS boto library. You will find additional infos here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html. For pandas any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host is expected.\n",
    "\n",
    "For text data, most of the time you can read it as line-by-line files or use Pandas to read it as a DataFrame by specify a delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_s3_location = \"s3://{}/{}/{}\".format(bucket, prefix, filename) # S3 URL\n",
    "s3_tabular_data = pd.read_csv(data_s3_location, sep=\"\\t\", header=None)\n",
    "s3_tabular_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Json files, depending on the structure, you can also use `Pandas` `read_json` function to read it if it's a flat json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'For the last 8 years of his life, Galileo was...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'No. 2: 1912 Olympian; football star at Carlis...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'The city of Yuma in this state has a record a...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'In 1963, live on \"The Art Linkletter Show\", t...</td>\n",
       "      <td>$200</td>\n",
       "      <td>McDonald\\'s</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'Signer of the Dec. of Indep., framer of the C...</td>\n",
       "      <td>$200</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          category    air_date  \\\n",
       "0                          HISTORY  2004-12-31   \n",
       "1  ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
       "2      EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
       "3                 THE COMPANY LINE  2004-12-31   \n",
       "4              EPITAPHS & TRIBUTES  2004-12-31   \n",
       "\n",
       "                                            question value       answer  \\\n",
       "0  'For the last 8 years of his life, Galileo was...  $200   Copernicus   \n",
       "1  'No. 2: 1912 Olympian; football star at Carlis...  $200   Jim Thorpe   \n",
       "2  'The city of Yuma in this state has a record a...  $200      Arizona   \n",
       "3  'In 1963, live on \"The Art Linkletter Show\", t...  $200  McDonald\\'s   \n",
       "4  'Signer of the Dec. of Indep., framer of the C...  $200   John Adams   \n",
       "\n",
       "       round  show_number  \n",
       "0  Jeopardy!         4680  \n",
       "1  Jeopardy!         4680  \n",
       "2  Jeopardy!         4680  \n",
       "3  Jeopardy!         4680  \n",
       "4  Jeopardy!         4680  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json_location = \"s3://{}/{}/{}\".format(bucket, prefix_json, filename_json)\n",
    "s3_tabular_data_json = pd.read_json(data_json_location, orient='records')\n",
    "s3_tabular_data_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Use AWS Native methods\n",
    "https://s3fs.readthedocs.io/en/latest/ <br>\n",
    "S3Fs is a Pythonic file interface to S3. It builds on top of botocore. The top-level class S3FileSystem holds connection information and allows typical file-system style operations like cp, mv, ls, du, glob, etc., as well as put/get of local files to/from S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sagemaker-us-east-1-942158337222/text_spam/spam/SMSSpamCollection.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem()\n",
    "data_s3fs_location = \"s3://{}/{}/\".format(bucket, prefix)\n",
    "# To List all files in your accessible bucket\n",
    "fs.ls(data_s3fs_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ham  \\\n",
      "0   ham   \n",
      "1  spam   \n",
      "\n",
      "  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
      "0                      Ok lar... Joking wif u oni...                                                               \n",
      "1  Free entry in 2 a wkly comp to win FA Cup fina...                                                               \n"
     ]
    }
   ],
   "source": [
    "# open it directly with s3fs\n",
    "data_s3fs_location = \"s3://{}/{}/{}\".format(bucket, prefix, filename) # S3 URL\n",
    "with fs.open(data_s3fs_location) as f:\n",
    "    print(pd.read_csv(f, sep = '\\t', nrows = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_obj =boto3.client('s3')\n",
    "key = \"{}/{}\".format(prefix_json,filename_json)\n",
    "s3_clientobj = s3_obj.get_object(Bucket=bucket, Key=key)\n",
    "s3_clientdata = s3_clientobj['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"category\": \"HISTORY\", \"air_date\": \"2004-12-31\", \"question\": \"\\'For the last 8 years of his life, Galileo was under house arrest for espousing this man\\'s theory\\'\", \"value\": \"$200\", \"answer\": \"Copernicus\", \"round\": \"Jeopardy!\", \"show_number\": \"4680\"}, {\"category\": \"ESPN\\'s TOP 10 ALL-TIME ATHLETES\", \"air_date\": \"2004-12-31\", \"question\": \"\\'No. 2: 1912 Olympian; football star at Carlisle Indian School; 6 MLB seasons with the Reds, Giants & Braves\\'\", \"value\": \"$200\", \"answer\": \"Jim Thorpe\", \"round\": \"Jeopardy!\", \"show_number\": \"4680\"}, {\"category\": \"EVERYBODY TALKS ABOUT IT...\", \"air_date\": \"2004-12-31\", \"question\": \"\\'The city of Yuma in this state has a record average of 4,055 hours of sunshine each year\\'\", \"value\": \"$200\", \"answer\": \"Arizona\", \"round\": \"Jeopardy!\", \"show_number\": \"4680\"}, {\"category\": \"THE COMPANY LINE\", \"air_date\": \"2004-12-31\", \"question\": \"\\'In 1963, live on \\\\\"The Art Linkletter Show\\\\\", this company served its billionth burger\\'\", \"value\": \"$200\", \"answer\": \"McDonald\\\\\\\\\\''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_clientdata[:1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
